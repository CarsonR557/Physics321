{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the diffusion equation using a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we find the solution of the diffusion equation using a neural network. The diffusion equation in one dimension in its most general form is given by\n",
    "$$\\frac{du}{dt} = \\frac{d^2u}{dx^2},$$ \n",
    "where \n",
    "$x \\in [0,1]$ and $t \\geq 0$. \n",
    "The initial condition is given by \n",
    "$$u(x,0) = \\sin(\\pi x)$$\n",
    "and the boundary conditions are given by\n",
    "$$u(0,t) = u(1,t) = 0.$$\n",
    "We use the trial function \n",
    "$$g_t = (1-t)\\sin(\\pi x) + (1-x)*t*h_1(N)$$\n",
    "\n",
    "The first step we will do is to find the best network and number of iterations in training by testing for different combinations. The code for solving the diffusion equation using the neural network are found in diffusion_solvers.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 / 100000 loss:  10.685791\n",
      "Step: 1000 / 100000 loss:  5.1547112\n",
      "Step: 2000 / 100000 loss:  4.8309\n",
      "Step: 3000 / 100000 loss:  4.531816\n",
      "Step: 4000 / 100000 loss:  4.20473\n",
      "Step: 5000 / 100000 loss:  3.8860333\n",
      "Step: 6000 / 100000 loss:  3.6086063\n",
      "Step: 7000 / 100000 loss:  3.3747718\n",
      "Step: 8000 / 100000 loss:  3.0742834\n",
      "Step: 9000 / 100000 loss:  2.5098808\n",
      "Step: 10000 / 100000 loss:  2.2157342\n",
      "Step: 11000 / 100000 loss:  1.9023384\n",
      "Step: 12000 / 100000 loss:  1.624308\n",
      "Step: 13000 / 100000 loss:  1.4180828\n",
      "Step: 14000 / 100000 loss:  1.2683553\n",
      "Step: 15000 / 100000 loss:  1.1494218\n",
      "Step: 16000 / 100000 loss:  1.042746\n",
      "Step: 17000 / 100000 loss:  0.9347981\n",
      "Step: 18000 / 100000 loss:  0.8273896\n",
      "Step: 19000 / 100000 loss:  0.74542296\n",
      "Step: 20000 / 100000 loss:  0.67532593\n",
      "Step: 21000 / 100000 loss:  0.5950392\n",
      "Step: 22000 / 100000 loss:  0.5147199\n",
      "Step: 23000 / 100000 loss:  0.44384915\n",
      "Step: 24000 / 100000 loss:  0.39509255\n",
      "Step: 25000 / 100000 loss:  0.3663866\n",
      "Step: 26000 / 100000 loss:  0.34813464\n",
      "Step: 27000 / 100000 loss:  0.33435538\n",
      "Step: 28000 / 100000 loss:  0.32269654\n",
      "Step: 29000 / 100000 loss:  0.31230852\n",
      "Step: 30000 / 100000 loss:  0.30283898\n",
      "Step: 31000 / 100000 loss:  0.29410702\n",
      "Step: 32000 / 100000 loss:  0.28600112\n",
      "Step: 33000 / 100000 loss:  0.27844256\n",
      "Step: 34000 / 100000 loss:  0.27137056\n",
      "Step: 35000 / 100000 loss:  0.26473552\n",
      "Step: 36000 / 100000 loss:  0.2584953\n",
      "Step: 37000 / 100000 loss:  0.2526133\n",
      "Step: 38000 / 100000 loss:  0.24705742\n",
      "Step: 39000 / 100000 loss:  0.24179897\n",
      "Step: 40000 / 100000 loss:  0.23681247\n",
      "Step: 41000 / 100000 loss:  0.23207507\n",
      "Step: 42000 / 100000 loss:  0.22756615\n",
      "Step: 43000 / 100000 loss:  0.22326735\n",
      "Step: 44000 / 100000 loss:  0.21916224\n",
      "Step: 45000 / 100000 loss:  0.21523596\n",
      "Step: 46000 / 100000 loss:  0.21147536\n",
      "Step: 47000 / 100000 loss:  0.20786873\n",
      "Step: 48000 / 100000 loss:  0.20440565\n",
      "Step: 49000 / 100000 loss:  0.20107685\n",
      "Step: 50000 / 100000 loss:  0.19787416\n",
      "Step: 51000 / 100000 loss:  0.19479042\n",
      "Step: 52000 / 100000 loss:  0.19181915\n",
      "Step: 53000 / 100000 loss:  0.18895465\n",
      "Step: 54000 / 100000 loss:  0.18619178\n",
      "Step: 55000 / 100000 loss:  0.18352592\n",
      "Step: 56000 / 100000 loss:  0.18095267\n",
      "Step: 57000 / 100000 loss:  0.17846803\n",
      "Step: 58000 / 100000 loss:  0.17606817\n",
      "Step: 59000 / 100000 loss:  0.17374949\n",
      "Step: 60000 / 100000 loss:  0.1715083\n",
      "Step: 61000 / 100000 loss:  0.16934124\n",
      "Step: 62000 / 100000 loss:  0.16724487\n",
      "Step: 63000 / 100000 loss:  0.16521592\n",
      "Step: 64000 / 100000 loss:  0.16325112\n",
      "Step: 65000 / 100000 loss:  0.16134731\n",
      "Step: 66000 / 100000 loss:  0.1595014\n",
      "Step: 67000 / 100000 loss:  0.15771045\n",
      "Step: 68000 / 100000 loss:  0.15597154\n",
      "Step: 69000 / 100000 loss:  0.15428197\n",
      "Step: 70000 / 100000 loss:  0.15263906\n",
      "Step: 71000 / 100000 loss:  0.15104029\n",
      "Step: 72000 / 100000 loss:  0.14948328\n",
      "Step: 73000 / 100000 loss:  0.14796577\n",
      "Step: 74000 / 100000 loss:  0.14648561\n",
      "Step: 75000 / 100000 loss:  0.14504084\n",
      "Step: 76000 / 100000 loss:  0.1436295\n",
      "Step: 77000 / 100000 loss:  0.14224988\n",
      "Step: 78000 / 100000 loss:  0.14090031\n",
      "Step: 79000 / 100000 loss:  0.13957922\n",
      "Step: 80000 / 100000 loss:  0.13828522\n",
      "Step: 81000 / 100000 loss:  0.13701692\n",
      "Step: 82000 / 100000 loss:  0.13577314\n",
      "Step: 83000 / 100000 loss:  0.13455267\n",
      "Step: 84000 / 100000 loss:  0.13335444\n",
      "Step: 85000 / 100000 loss:  0.13217744\n",
      "Step: 86000 / 100000 loss:  0.13102078\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import time\n",
    "from diffusion_solvers import nn_diffusion_solver\n",
    "\n",
    "Nx = 10\n",
    "x_np = np.linspace(0,1,Nx)\n",
    "\n",
    "Nt = 10\n",
    "t_np = np.linspace(0,1,Nt)\n",
    "\n",
    "X,T = np.meshgrid(x_np, t_np)\n",
    "\n",
    "x = X.ravel()\n",
    "t = T.ravel()\n",
    "\n",
    "x = tf.reshape(tf.convert_to_tensor(x),shape=(-1,1))\n",
    "t = tf.reshape(tf.convert_to_tensor(t),shape=(-1,1))\n",
    "\n",
    "points = tf.concat([x,t],1)\n",
    "\n",
    "num_iter = 100000\n",
    "num_hidden_neurons = [50]\n",
    "\n",
    "lr = 0.01\n",
    "reg_param=0\n",
    "\n",
    "#Calculates the analytical solution and the neural network solution. \n",
    "analytic, nn, losses, iterations = nn_diffusion_solver(num_iter, lr, reg_param, num_hidden_neurons, points, x, t)\n",
    "\n",
    "#Calculating the error of the neural network solution compared to the analytical solution. \n",
    "error = np.abs(analytic - nn)\n",
    "\n",
    "print('Max error = ', np.max(error))\n",
    "print(\"MSE = \", np.mean(error**2))\n",
    "\n",
    "#Converts back to original grid. \n",
    "G_analytic = analytic.reshape((Nt,Nx))\n",
    "G_dnn = nn.reshape((Nt,Nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(iterations, losses)\n",
    "plt.title(\"Loss over iterations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now study the solution found with neural network compared to the analytical solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the neural network solution, the analytical solution and the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,T = np.meshgrid(x_np, t_np)\n",
    "\n",
    "diff = np.abs(G_analytic - G_dnn)\n",
    "MSE = np.mean((G_analytic-G_dnn)**2)\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "fig = plt.figure(figsize=(23,10))\n",
    "\n",
    "ax1 = fig.add_subplot(1,3,1, projection=\"3d\")\n",
    "ax1.plot_surface(X,T,G_dnn,linewidth=0,antialiased=False,cmap=cm.viridis)\n",
    "ax1.tick_params(axis='z', pad=15)\n",
    "ax1.set_xlabel('$x$', labelpad=10, fontsize=20)\n",
    "ax1.set_ylabel('$t$', labelpad=10, fontsize=20)\n",
    "ax1.set_title(\"NN solution\")\n",
    "\n",
    "ax2 = fig.add_subplot(1,3,2, projection=\"3d\")\n",
    "ax2.plot_surface(X,T,G_analytic,linewidth=0,antialiased=False,cmap=cm.viridis)\n",
    "ax2.tick_params(axis='z', pad=15)\n",
    "ax2.set_xlabel('$x$', labelpad=10, fontsize=20)\n",
    "ax2.set_ylabel('$t$', labelpad=10, fontsize=20)\n",
    "ax2.set_title(\"Analytic solution\")\n",
    "\n",
    "ax3 = fig.add_subplot(1,3,3, projection=\"3d\")\n",
    "ax3.plot_surface(X,T,diff,linewidth=0,antialiased=False,cmap=cm.viridis)\n",
    "ax3.tick_params(axis='z', pad=15)\n",
    "ax3.set_xlabel('$x$', labelpad=10, fontsize=20)\n",
    "ax3.set_ylabel('$t$', labelpad=10, fontsize=20)\n",
    "ax3.set_title(\"Error\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the neural network solution and the analytical solution for two different times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "dt = 1/Nt\n",
    "dx = 1/Nx\n",
    "\n",
    "time_1 = 0.02\n",
    "time_2 = 0.3\n",
    "\n",
    "plot_index_1 = int(time_1/dt)\n",
    "plot_index_2 = int(time_2/dt)\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.xlabel(\"X\", fontsize=20)\n",
    "plt.ylabel(\"u\", fontsize=20)\n",
    "plt.plot(G_dnn[plot_index_1,:], linestyle=\"--\",marker=\"x\", alpha= 0.9)\n",
    "plt.plot(G_analytic[plot_index_1,:], linestyle=\"--\",marker=\"x\", alpha= 0.9)\n",
    "plt.title(r\"t = %.2f\" %time_1)\n",
    "plt.legend([\"NN\", \"Analytic\"])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.xlabel(\"X\", fontsize=20)\n",
    "plt.ylabel(\"u\", fontsize=20)\n",
    "plt.plot(G_dnn[plot_index_2,:], linestyle=\"--\",marker=\"x\", alpha= 0.9)\n",
    "plt.plot(G_analytic[plot_index_2,:], linestyle=\"--\",marker=\"x\", alpha= 0.9)\n",
    "plt.title(r\"t = %.2f\" %time_2)\n",
    "plt.legend([\"NN\", \"Analytic\"])\n",
    "plt.ylim((-0.1,1))\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "filename = (\"solution_and_error_nn_1D_dt_%s_dx_%s.png\"%(dt,dx)).replace(\".\",\"_\",2)\n",
    "plt.savefig(r\"Plots/\" + filename)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we compare the results from neural network with the ones from using the forward Euler method for two different times.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by setting up the problems parameters and the networks parameters. Then finds the solution using the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import time\n",
    "\n",
    "from diffusion_solvers import nn_diffusion_solver\n",
    "\n",
    "dx = 0.1\n",
    "dt = 0.005\n",
    "\n",
    "Nx = int(1/dx)+1\n",
    "x_np = np.linspace(0,1,Nx)\n",
    "\n",
    "Nt = int(1/dt)+1\n",
    "t_np = np.linspace(0,1,Nt)\n",
    "\n",
    "X,T = np.meshgrid(x_np, t_np)\n",
    "\n",
    "x = X.ravel()\n",
    "t = T.ravel()\n",
    "\n",
    "## The construction phase\n",
    "\n",
    "zeros = tf.reshape(tf.convert_to_tensor(np.zeros(x.shape)),shape=(-1,1))\n",
    "x = tf.reshape(tf.convert_to_tensor(x),shape=(-1,1))\n",
    "t = tf.reshape(tf.convert_to_tensor(t),shape=(-1,1))\n",
    "\n",
    "points = tf.concat([x,t],1)\n",
    "\n",
    "num_iter = 100000\n",
    "num_hidden_neurons = [50]\n",
    "\n",
    "lr = 0.01\n",
    "reg_param = 0\n",
    "\n",
    "X = tf.convert_to_tensor(X)\n",
    "T = tf.convert_to_tensor(T)\n",
    "\n",
    "analytic, nn, losses, iterations = nn_diffusion_solver(num_iter, lr, reg_param, num_hidden_neurons, points, x, t)\n",
    "\n",
    "#Calculating the error of the neural network solution compared to the analytical solution. \n",
    "error = np.abs(analytic - nn)\n",
    "\n",
    "print('Max error = ', np.max(error))\n",
    "print(\"MSE = \", np.mean(error**2))\n",
    "# print(\"Training-time = %.2f seconds\" %(time_end - time_start))\n",
    "\n",
    "#Converts back to original grid. \n",
    "G_analytic = analytic.reshape((Nt,Nx))\n",
    "G_dnn = nn.reshape((Nt,Nx))\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(iterations, losses)\n",
    "plt.title(\"Loss over iterations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After finding the neural network solution, we compare it to the forward euler method for the same grid-size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_solvers import forward_euler, analytic_solution_1D\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x_min = 0\n",
    "x_max = 1\n",
    "\n",
    "#Choose steplengths to test for different grid sizes. \n",
    "dx = 0.1    #Spatial step\n",
    "dt = 0.005#0.5*(dx**2)#1e-3   #Time-step\n",
    "\n",
    "t = 1  #Max time\n",
    "\n",
    "num_x_values = (x_max - x_min)/dx\n",
    "num_t_values = float(t)/dt\n",
    "\n",
    "x_values = np.linspace(x_min, x_max, num_x_values +1)\n",
    "t_values = np.linspace(0, t, num_t_values+1)\n",
    "\n",
    "#Defining the boundary and intitial conditions.\n",
    "g = (lambda x : np.sin(np.pi*x))\n",
    "a = (lambda t : 0)\n",
    "b = (lambda t : 0)\n",
    "\n",
    "#Choose time to plot and calculate the index of this time.\n",
    "plot_time = 0.3\n",
    "plot_index = int(plot_time*t/dt)\n",
    "\n",
    "params = {'figure.figsize': (20, 5), \"legend.fontsize\":15, \"axes.labelsize\": 15}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "\n",
    "#Plotting the solution from the different numerical methods.\n",
    "u_forward_euler = forward_euler(x_min, x_max, dx, dt, t, g, a, b)\n",
    "analytic_solution = analytic_solution_1D(x_values, t_values[plot_index])\n",
    "\n",
    "\n",
    "plt.plot(x_values, u_forward_euler[plot_index,:], linestyle=\"--\", marker = \"x\", alpha = 0.9)\n",
    "\n",
    "plt.plot(x_values, analytic_solution, alpha = 0.8)\n",
    "\n",
    "plt.plot(x_values, G_dnn[plot_index,:])\n",
    "\n",
    "plt.legend([\"Forward Euler\",\"Analytic\", \"Nerual network\"])\n",
    "plt.title(\"Solution for dx = %.4f, dt = %.5f, t = %.3f\" %(dx,dt, plot_time), fontsize=20)\n",
    "plt.xlabel(\"X\", fontsize=20)\n",
    "plt.ylabel(\"u\", fontsize=20)\n",
    "plt.ylim(-0.1,1.1)\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "#Plotting the error for the different numerical methods compared to the analytical solution.\n",
    "error_forward_euler = analytic_solution - u_forward_euler[plot_index,:]\n",
    "error_neural_network = analytic_solution - G_dnn[plot_index,:]\n",
    "\n",
    "plt.plot(x_values, abs(error_forward_euler), linestyle=\"--\",marker=\"x\", alpha= 0.9)\n",
    "plt.plot(x_values, abs(error_neural_network), linestyle=\"--\",marker=\"x\", alpha= 0.9)\n",
    "\n",
    "\n",
    "# plt.scatter(x_values, (error_forward_euler), alpha = 0.5, s = 20)\n",
    "# plt.scatter(x_values, (error_backward_euler), alpha = 0.5, s=20)\n",
    "# plt.scatter(x_values, (error_cn), alpha = 0.5,s=20)\n",
    "\n",
    "plt.xlabel(\"X\", fontsize=20)\n",
    "plt.ylabel(\"u\", fontsize=20)\n",
    "plt.title(\"Error for dx = %.4f, dt = %.5f, t = %.3f\" %(dx,dt, plot_time), fontsize=20)\n",
    "plt.legend([\"Forward Euler\", \"Neural network\"])\n",
    "plt.subplots_adjust( wspace=0.2)\n",
    "\n",
    "filename = (\"nn_solution_and_error_1D_dt_%s_dx_%s_t_%.3f.png\"%(dt,dx, plot_time)).replace(\".\",\"_\",3)\n",
    "plt.savefig(r\"Plots/\" + filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"MSE forward Euler = \", np.mean(sum(error_forward_euler**2)))\n",
    "print(\"MSE nn = \", np.mean(sum(error_neural_network**2)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
